<TEI xmlns="http://www.tei-c.org/ns/1.0">
    <teiHeader>
        <fileDesc>
            <titleStmt>
                <title type="full">
                    <title type="main">Dependenzbasierte syntaktische Komplexitätsmaße</title>
                    <title type="sub"/>
                </title>
                <author ref="#person__thomas-proisl-fau-de">
                    <persName>
                        <surname>Proisl</surname>
                        <forename>Thomas</forename>
                    </persName>
                    <affiliation ref="#org__44">Friedrich-Alexander-Universität Erlangen-Nürnberg, Deutschland</affiliation>
                    <email>thomas.proisl@fau.de</email>
                </author>
                <author ref="#person__leonard-konle-uni-wuerzburg-de">
                    <persName>
                        <surname>Konle</surname>
                        <forename>Leonard</forename>
                    </persName>
                    <affiliation ref="#org__36">Julius-Maximilians-Universität Würzburg</affiliation>
                    <email>leonard.konle@uni-wuerzburg.de</email>
                </author>
                <author ref="#person__stefan-evert-fau-de">
                    <persName>
                        <surname>Evert</surname>
                        <forename>Stefan</forename>
                    </persName>
                    <affiliation ref="#org__44">Friedrich-Alexander-Universität Erlangen-Nürnberg, Deutschland</affiliation>
                    <email>stefan.evert@fau.de</email>
                </author>
                <author ref="#person__fotis-jannidis-uni-wuerzburg-de">
                    <persName>
                        <surname>Jannidis</surname>
                        <forename>Fotis</forename>
                    </persName>
                    <affiliation ref="#org__36">Julius-Maximilians-Universität Würzburg</affiliation>
                    <email>fotis.jannidis@uni-wuerzburg.de</email>
                </author>
            </titleStmt>
            <editionStmt>
                <edition>
                    <date>2018-10-15T10:23:14.497763862</date>
                </edition>
            </editionStmt>
            <publicationStmt>
                <publisher>Prof. Dr. Alexander Mehler</publisher>
                <address>
                    <addrLine>Goethe-Universität Frankfurt am Main</addrLine>
                    <addrLine>Text Technology Lab, Fachbereich für Informatik und Mathematik</addrLine>
                    <addrLine>Robert-Mayer-Straße 10</addrLine>
                    <addrLine>60325 Frankfurt am Main</addrLine>
                </address>
            </publicationStmt>
            <sourceDesc>
                <p>Converted from an OASIS Open Document</p>
            </sourceDesc>
        </fileDesc>
        <encodingDesc>
            <appInfo>
                <application ident="DHCONVALIDATOR" version="1.22">
                    <label>DHConvalidator</label>
                </application>
            </appInfo>
        </encodingDesc>
        <profileDesc>
            <textClass>
                <keywords scheme="ConfTool" n="category">
                    <term>Paper</term>
                </keywords>
                <keywords scheme="ConfTool" n="subcategory">
                    <term>Posterpräsentation</term>
                </keywords>
                <keywords scheme="ConfTool" n="keywords">
                    <term>Komplexität</term>
                    <term>Syntax</term>
                    <term>Dependenzparsing</term>
                </keywords>
                <keywords scheme="ConfTool" n="topics">
                    <term>Bewertung</term>
                    <term>Stilistische Analyse</term>
                    <term>Literatur</term>
                    <term>Text</term>
                </keywords>
            </textClass>
        </profileDesc>
    </teiHeader>
    <text>
        <body>
            <p>Die Beschreibung der Komplexität von (literarischen) Texten muss für jeden Aspekt, also Vokabular, Satz/Syntax, uneigentliche Rede, Intertextualität usw., gesondert vorgenommen werden. Im Folgenden beschäftigen wir uns mit dem Aspekt Satz/Syntax, der lange Zeit vor allem über die durchschnittliche Satzlänge erfasst wurde (Sherman 1893, Flesch 1948, Best 2005). Dabei bleibt aber, so eine naheliegende Vermutung, die interne syntaktische Komplexität eines Satzes unberücksichtigt. Die meisten Leser würden z. B. einen stark verschachtelten Satz als syntaktisch komplexer einstufen als eine gleich lange parataktische Konstruktion. Unsere Arbeit zielt darauf, diesen Aspekt unter Verwendung der im 
                <hi rend="italic">Natural Language Processing</hi> (NLP) weitverbreiteten dependenzbasierten Syntaxmodelle messen zu können. Kontext unserer Überlegungen ist das Unterfangen, Textkomplexität quantitativ zu erfassen. So können Annahmen in der Literaturwissenschaft und Linguistik über die unterschiedliche Komplexität der Texte bestimmter Gattungen, Autoren oder gar von Teilsystemen, z. B. populäre Literatur vs. Hochliteratur, empirisch überprüft werden. Bislang wird die syntaktische Komplexität überwiegend auf Phrasenstrukturbäumen ermittelt (für eine Übersicht siehe Vajjala Balakrishna 2015: 51–52), allerdings fehlen dafür in vielen Sprachen verlässliche NLP-Werkzeuge. Auf der anderen Seite stehen mit dem Universal-Dependencies-Projekt (Nivre u. a. 2016)
                <note xml:id="ftn1" place="foot" n="1">
                    <ptr target="http://universaldependencies.org/"/>
                </note> bereits mehr als 100 manuell erstellte Baumbanken in über 60 Sprachen (darunter auch ältere Sprachstufen) in einer sprachübergreifend konsistenten Annotation zur Verfügung und es gibt computerlinguistische Pipelines wie etwa UDPipe (Straka und Straková 2017),
                <note xml:id="ftn2" place="foot" n="2">
                    <ptr target="http://ufal.mff.cuni.cz/udpipe"/>
                </note> die Texte in allen diesen Sprachen tokenisieren, taggen, lemmatisieren und parsen können. Von daher liegt es nahe, die syntaktische Komplexität von Texten auch mit dependenzbasierten Maßen zu messen. Einen ersten Vergleich von dependenzbasierten Komplexitätsmaßen hat Oya (2012) durchgeführt.
            </p>
            <p>Für unsere Untersuchung verwenden wir ein deutschsprachiges Korpus von knapp 1.000 Romanen aus den letzten 60 Jahren. Bei etwa 85% der Texte handelt es sich um Heftromane (Romanzen (13%), Science Fiction (65%) und Horror (7%)), bei den restlichen 15% um Hochliteratur (kanonische Texte und/oder Literaturpreisträger). Alle Texte wurden mit dem DARIAH-DKPro-Wrapper (Jannidis u. a. 2016)
                <note xml:id="ftn3" place="foot" n="3">
                    <ptr target="https://github.com/DARIAH-DE/DARIAH-DKPro-Wrapper"/>
                </note> verarbeitet.
            </p>
            <p>Syntaktische Komplexitätsmaße sind typischerweise auf Satzebene definiert. Wir berechnen für jeden Satz die folgenden Maße:
                <note xml:id="ftn4" place="foot" n="4">
                    <ptr target="https://github.com/tsproisl/Linguistic_and_Stylistic_Complexity"/>
                </note>
            </p>
            <list type="unordered">
                <item>
                    <hi rend="italic">Average dependency distance</hi> (= durchschnittlicher Abstand zweier durch eine Dependenzrelation verbundener Tokens (Liu 2008; Oya 2011))
                </item>
                <item>
                    <hi rend="italic">Closeness centrality</hi> des Wurzelknotens (= Kehrwert der durchschnittlichen Länge der kürzesten Pfade vom Wurzelknoten zu allen anderen Knoten); hier bedeutet ein kleinerer Wert eine höhere Komplexität
                </item>
                <item>
                    <hi rend="italic">Closeness centralization</hi> (= Erweiterung der closeness centrality von einem einzelnen Knoten auf einen ganzen Graphen (Freeman 1978)); hier bedeutet ein kleinerer Wert eine höhere Komplexität
                </item>
                <item>
                    <hi rend="italic">Outdegree centralization</hi>, die Erweiterung der 
                    <hi rend="italic">outdegree centrality</hi> (= Anzahl der von einem Knoten ausgehenden Kanten) von einem einzelnen Knoten auf einen ganzen Graph (Freeman 1978); hier bedeutet ein kleinerer Wert eine höhere Komplexität
                </item>
                <item>Durchschnittliche Anzahl von Dependenten pro Token</item>
                <item>Höhe des Dependenzbaums (= der längste kürzeste Pfad vom Wurzelknoten zu einem anderen Knoten)</item>
            </list>
            <p>Zum Vergleich ermitteln wir zusätzlich die Satzlänge, d. h. die Anzahl Tokens pro Satz. Um einen Wert für die syntaktische Komplexität eines gesamten Textes zu erhalten, bilden wir jeweils die Mittelwerte über alle Sätze.</p>
            <p>Die Ergebnisse sind in den folgenden sechs Grafiken als Boxplots dargestellt (der weiße Kreis markiert zusätzlich das arithmetische Mittel):</p>
            <p>
                <figure>
                    <graphic url="Pictures/68845ec25494ae1982a7a30987f775c8.png"/>
                </figure>
            </p>
            <p>Average dependency distance</p>
            <p>
                <figure>
                    <graphic url="Pictures/1f62594c2dfb29b65e70c58e7ee284e7.png"/>
                </figure>
            </p>
            <p>Closeness centrality</p>
            <p>
                <figure>
                    <graphic url="Pictures/ff69c8b4433888f12f70e7f1fb1605a5.png"/>
                </figure>
            </p>
            <p>Closeness centralization</p>
            <p>
                <figure>
                    <graphic url="Pictures/d922d2d76c44248f84b586d67e3aa57e.png"/>
                </figure>
            </p>
            <p>Outdegree centralization</p>
            <p>
                <figure>
                    <graphic url="Pictures/23d73a7b0099d30df4446a04ab753ac7.png"/>
                </figure>
            </p>
            <p>Dependenten pro Token</p>
            <p>
                <figure>
                    <graphic url="Pictures/1e6207df237e2b0b63ed26529241b14e.png"/>
                </figure>
            </p>
            <p>Höhe des Dependenzbaums</p>
            <p>
                <figure>
                    <graphic url="Pictures/245096169bf192b9c8122d44f23b3a77.png"/>
                </figure>Satzlänge
            </p>
            <p>Die Boxplots für Hoch- und Schemaliteratur insgesamt würden nahelegen, dass es für die untersuchten Maße keinen statistisch signifikanten Unterschied zwischen Hoch- und Schemaliteratur gibt. Die Detailansicht für die einzelnen Unterkategorien der Schemaliteratur bringt jedoch Interessantes zu Tage. Zwischen den einzelnen Kategorien untereinander gibt es deutlich ausgeprägtere Unterschiede als zwischen Hoch- und Schemaliteratur insgesamt. Besonders auffällig ist, dass fast alle Maße eine signifikant höhere Komplexität für Science-Fiction-Literatur anzeigen als für Romanzen oder Horrorhefte. Wahrscheinlich liegt das daran, dass das SF-Teilkorpus aus Romanen der Serie ‚Perry Rhodan‘ besteht, der auch von literaturwissenschaftlicher Seite eine Sonderrolle innerhalb der Heftromane zugeschrieben wird (Nast 2017). Ebenfalls auffällig ist, dass alle Maße eine viel größere Streuung für die Hochliteratur aufweisen als für die zahlenmäßig viel stärker vertretene Schemaliteratur. Dafür bieten sich zwei Erklärungsmodelle an: a) die Hochliteratur besteht eigentlich aus mehreren Gattungen, die sich wiederum deutlich voneinander unterscheiden; b) der Unterschied lässt sich auf die unterschiedlichen Eigenschaften der literarischen Teilfelder zurückführen – In der Hochliteratur dominiert der Wert Variation/Überraschung, in den populären Genres der Wert Erwartbarkeit, wahrscheinlich sogar erzwungen durch Lektoren.</p>
            <p>
                <figure>
                    <graphic url="Pictures/a66dfd02e1a2a1359940fc1174e5638c.png"/>
                </figure>
            </p>
            <p>Pearson-Korrelationen zwischen den Komplexitätsmaßen</p>
            <p>Eine Analyse der Pearson-Korrelationen zwischen den Komplexitätsmaßen zeigt, dass einige davon nahezu perfekt korrelieren.
                <note xml:id="ftn0" place="foot" n="5">
                    <hi rend="italic">Closeness centrality</hi>, 
                    <hi rend="italic">closeness centralization</hi> und 
                    <hi rend="italic">outdegree centralization</hi> wurden für diese Analyse mit −1 multipliziert, damit für alle Maße größere Werte eine höhere Komplexität anzeigen.
                </note> So beispielsweise 
                <hi rend="italic">closeness centralization</hi> und 
                <hi rend="italic">outdegree centralization</hi> (r = 0,99), 
                <hi rend="italic">closeness centrality</hi> und 
                <hi rend="italic">closeness centralization</hi> (r = 0,98), die Höhe des Dependenzbaums und die Satzlänge (r = 0,97) und 
                <hi rend="italic">closeness centrality</hi> und die Anzahl Dependenten pro Wort (r = 0,96). 
                <hi rend="italic">Average dependency distance</hi> ist den anderen dependenzbasierten Maßen am unähnlichsten (0,50 ≤ r ≤ 0,78). Insgesamt betrachtet, korrelieren die verwendeten Maße zwar recht robust mit der durchschnittlichen Satzlänge (0,65 ≤ r ≤ 0,83), scheinen sich aber (mit Ausnahme der Höhe des Dependenzbaums) doch auch ausreichend stark von ihr zu unterscheiden um den durch das Parsen der Texte und Berechnen der dependenzbasierten Maße entstehenden Mehraufwand zu rechtfertigen. Zusätzlich könnte es durch die gezielte Entwicklung längenkorrigierter Maße gelingen, unterschiedliche Aspekte syntaktischer Komplexität getrennt voneinander zu erfassen.
            </p>
        </body>
        <back>
            <div type="bibliogr">
                <listBibl>
                    <head>Bibliographie</head>
                    <bibl>
                        <rs type="bibl" ref="#bibl__3021">Best, Karl-Heinz (2005): „Satzlänge“, in: Köhler, Reinhard / Altmann, Gabriel / Piotrowski, Rajmund G.: Quantitative Linguistik / Quantitative Linguistics. Berlin: de Gruyter-Mouton 298–304.</rs></bibl>
                    <bibl>
                        <rs type="bibl" ref="#bibl__3022">Flesch , Rudolf (1948): „A New Readability Yardstick“, in: Journal of Applied Psychology 32 Nr. 3: 221–233. 10.1037/h0057532[letzter Zugriff am 8. Januar 2019].</rs></bibl>
                    <bibl>
                        <rs type="bibl" ref="#bibl__3023">Freeman, Linton C. (1978): „Centrality in Social Networks. Conceptual Clarification“, in: Social Networks 1, Nr. 3: 215–239. 10.1016/0378-8733(78)90021-7 [letzter Zugriff am 15. Oktober 2018].</rs></bibl>
                    <bibl>
                        <rs type="bibl" ref="#bibl__3024">Jannidis, Fotis / Pernes, Stefan / Pielström, Steffen / Reger, Isabella / Reimers, Nils / Vitt, Thorsten (2016): „DARIAH-DKPro-Wrapper Output Format (DOF) Specification“, in: DARIAH-DE Working Papers 20. [letzter Zugriff am 15. Oktober 2018].</rs></bibl>
                    <bibl>
                        <rs type="bibl" ref="#bibl__3025">Liu, Haitao (2008): „Dependency Distance as a Metric of Language Comprehension Difficulty“, in: Journal of Cognitive Science 9, Nr. 2: 159–191. http://cogsci.snu.ac.kr/jcs/issue/vol9/no2/JCS_Vol_09_+No_2+p.+159+- +191+Dependency+Distance+as+a+Metric+of+Language+Comprehension+Difficulty.pdf [letzter Zugriff am 15. Oktober 2018].</rs></bibl>
                    <bibl>
                        <rs type="bibl" ref="#bibl__273">Nast, Mirjam (2017): „Perry Rhodan“ lesen. Zur Serialität der Lektürepraktiken einer Heftromanserie. Bielefeld: transcript.</rs></bibl>
                    <bibl>
                        <rs type="bibl" ref="#bibl__3026">Nivre, Joakim / de Marneffe, Marie-Catherine / Ginter, Filip / Goldberg, Yoav / Hajic, Jan / Manning, Christopher D. / McDonald, Ryan / Petrov, Slav / Pyysalo, Sampo / Silveira, Natalia / Tsarfaty, Reut / Zeman, Daniel (2016): „Universal Dependencies v1: A Multilingual Treebank Collection“, in: Calzolari, Nicoletta / Choukri, Khalid / Declerck, Thierry / Goggi, Sara / Grobelnik, Marko / Maegaard, Bente / Mariani, Joseph / Mazo, Hélène / Moreno, Asunción / Odijk, Jan / Piperidis, Stelios (eds.): Proceedings of the Tenth International Conference on Language Resources and Evaluation (LREC’16). Portorož: European Language Resources Association 1659–1666. [letzter Zugriff am 15. Oktober 2018].</rs></bibl>
                    <bibl>
                        <rs type="bibl" ref="#bibl__3027">Oya, Masanori (2011): „Syntactic Dependency Distance as Sentence Complexity Measure“, in: Proceedings of the 16th International Conference of Pan-Pacific Association of Applied Linguistics. 313–316. [letzter Zugriff am 15. Oktober 2018].</rs></bibl>
                    <bibl>
                        <rs type="bibl" ref="#bibl__3028">Sherman, Lucius Adelno (1893): Analytics of literature, a manual for the objective study of English prose and poetry. Boston: Ginn. [letzter Zugriff am 8. Januar 2019].</rs></bibl>
                    <bibl>
                        <rs type="bibl" ref="#bibl__3029">Straka, Milan / Straková, Jana (2017): „Tokenizing, POS Tagging, Lemmatizing and Parsing UD 2.0 with UDPipe“, in: Proceedings of the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies. Vancouver: Association for Computational Linguistics 88–99. [letzter Zugriff am 15. Oktober 2018].</rs></bibl>
                    <bibl>
                        <rs type="bibl" ref="#bibl__3030">Vajjala Balakrishna, Sowmya (2015): Analyzing Text Complexity and Text Simplification: Connecting Linguistics, Processing and Educational Applications. Dissertation, Eberhard-Karls-Universität Tübingen. [letzter Zugriff am 15. Oktober 2018].</rs></bibl>
                </listBibl>
            </div>
        </back>
    </text>
</TEI>